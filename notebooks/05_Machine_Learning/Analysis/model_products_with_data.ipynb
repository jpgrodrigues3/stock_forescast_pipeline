{"cells":[{"cell_type":"markdown","source":["## **Model Evaluation** - Products with data "],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"696a8aeb-c56d-4c74-afb6-d8bee9a941da"},{"cell_type":"code","source":["import mlflow\n","import pandas as pd\n","\n","# Step 1: Load experiment by name\n","experiment_name = \"Model_For_Products_WITH_data-ARIMA\"\n","experiment = mlflow.get_experiment_by_name(experiment_name)\n","\n","# Step 2: Get all runs for the experiment\n","runs_df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n","\n","# Step 3: Select relevant metrics columns\n","metrics_df = runs_df[[\n","    \"metrics.mae\",\n","    \"metrics.rmse\",\n","    \"metrics.r2\",\n","    \"metrics.accuracy\"\n","]].dropna()\n","\n","# Step 4: Calculate mean of each metric\n","mean_metrics = metrics_df.mean()\n","\n","# Step 5: Display results\n","print(\"Mean metrics across all runs:\")\n","print(mean_metrics)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"8784d349-fb52-4044-b81f-ad91d493f478","normalized_state":"finished","queued_time":"2025-07-03T00:52:17.4146702Z","session_start_time":"2025-07-03T00:52:17.4159763Z","execution_start_time":"2025-07-03T00:52:28.7620998Z","execution_finish_time":"2025-07-03T00:52:38.2435816Z","parent_msg_id":"378e7c3d-8741-4004-86d8-932daa54fc88"},"text/plain":"StatementMeta(, 8784d349-fb52-4044-b81f-ad91d493f478, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mean metrics across all runs:\nmetrics.mae         0.533544\nmetrics.rmse        0.574898\nmetrics.r2          0.000000\nmetrics.accuracy    0.729411\ndtype: float64\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a3b36532-96ad-4dc9-a1e8-81d19b6c7969"},{"cell_type":"code","source":["### Section 6: Conclusion and Summary\n","# This section provides a summary of the analysis.\n","\n","print(\"\\n--- Analysis Complete ---\")\n","print(\"The analysis has identified the best model for each store-product combination based on Mean Absolute Error (MAE).\")\n","print(\"The distribution of the best models is displayed above, showing which model performed best most frequently.\")\n","\n","# Optional: Calculate percentages\n","total_combinations = df_best_model.count()\n","if total_combinations > 0:\n","    best_model_percentages = best_model_counts.withColumn(\"percentage\", (col(\"count\") / total_combinations) * 100)\n","    print(\"\\nBest Model Distribution (with percentages):\")\n","    best_model_percentages.show(truncate=False)\n","else:\n","    print(\"\\nNo combinations found to analyze.\")\n","\n","\n","### Section 7: Contextualizing ARIMA MAE (and example for others)\n","# This section helps put the MAE values into perspective by comparing them to the\n","# typical range of the 'weekly_quantities_sold' data.\n","\n","print(\"\\n--- Contextualizing MAE Values with Source Data Statistics ---\")\n","\n","# --- Analysis for ARIMA model's source data ---\n","# This table was identified from the Model_For_Products_WITH_data-ARIMA (2).ipynb notebook.\n","arima_features_table = \"Machine_Learning.features.weekly_features_combos_with_data\"\n","\n","try:\n","    df_arima_features = spark.table(arima_features_table)\n","    print(f\"\\nDescriptive statistics for 'weekly_quantities_sold' from ARIMA model's source table ({arima_features_table}):\")\n","    df_arima_features.select(\"weekly_quantities_sold\").summary().show()\n","\n","    arima_sales_stats = df_arima_features.select(\n","        F.mean(\"weekly_quantities_sold\").alias(\"mean_sales\"),\n","        F.stddev(\"weekly_quantities_sold\").alias(\"stddev_sales\"),\n","        F.min(\"weekly_quantities_sold\").alias(\"min_sales\"),\n","        F.max(\"weekly_quantities_sold\").alias(\"max_sales\")\n","    ).collect()[0]\n","\n","    mean_sales_arima = arima_sales_stats[\"mean_sales\"]\n","    stddev_sales_arima = arima_sales_stats[\"stddev_sales\"]\n","    min_sales_arima = arima_sales_stats[\"min_sales\"]\n","    max_sales_arima = arima_sales_stats[\"max_sales\"]\n","\n","    # Assume you have the average MAE for ARIMA from MLflow search_runs\n","    arima_avg_mae = 0.534194\n","    arima_avg_r2 = 0.000000      # Add ARIMA's average R2\n","    arima_avg_accuracy = 0.730183 # Add ARIMA's average Accuracy (the problematic one)\n","\n","    print(f\"\\n--- Contextualizing ARIMA's Mean MAE ({arima_avg_mae:.6f}) ---\")\n","    print(f\"  Mean 'weekly_quantities_sold': {mean_sales_arima:.4f}\")\n","    print(f\"  Standard Deviation 'weekly_quantities_sold': {stddev_sales_arima:.4f}\")\n","    print(f\"  Min 'weekly_quantities_sold': {min_sales_arima:.4f}\")\n","    print(f\"  Max 'weekly_quantities_sold': {max_sales_arima:.4f}\")\n","\n","    if mean_sales_arima is not None and float(mean_sales_arima) != 0:\n","        mae_as_percent_of_mean = (arima_avg_mae / float(mean_sales_arima)) * 100\n","        print(f\"  MAE as % of Mean Sales: {mae_as_percent_of_mean:.2f}%\")\n","    else:\n","        print(\"  Cannot calculate MAE as % of Mean Sales (mean sales is zero or null).\")\n","\n","    if stddev_sales_arima is not None and float(stddev_sales_arima) != 0:\n","        mae_as_percent_of_stddev = (arima_avg_mae / float(stddev_sales_arima)) * 100\n","        print(f\"  MAE as % of Standard Deviation: {mae_as_percent_of_stddev:.2f}%\")\n","    else:\n","        print(\"  Cannot calculate MAE as % of Standard Deviation (stddev sales is zero or null).\")\n","\n","    # --- Add critical observations for ARIMA's R2 and Accuracy ---\n","    print(f\"\\n--- Additional ARIMA Metrics (Overall Average) ---\")\n","    print(f\"  Average R2: {arima_avg_r2:.6f}\")\n","    print(f\"  Average Accuracy: {arima_avg_accuracy:.6f}\")\n","    print(f\"  (Note: The average Accuracy of {arima_avg_accuracy:.6f} for ARIMA (1 - MAPE) implies a very high percentage error, indicating potential issues with the MAPE calculation, especially for time series with zero or near-zero actuals.)\")\n","\n","\n","except Exception as e:\n","    print(f\"Error accessing or processing data from {arima_features_table}: {e}\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":22,"statement_ids":[22],"state":"finished","livy_statement_state":"available","session_id":"6e10dd3b-1cf4-4a85-8432-fdf3468ca7fe","normalized_state":"finished","queued_time":"2025-07-03T00:29:08.1664427Z","session_start_time":null,"execution_start_time":"2025-07-03T00:29:08.1675848Z","execution_finish_time":"2025-07-03T00:29:13.6993061Z","parent_msg_id":"ceeb86de-3f8a-43ec-86ab-4bd6621aef3e"},"text/plain":"StatementMeta(, 6e10dd3b-1cf4-4a85-8432-fdf3468ca7fe, 22, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n--- Analysis Complete ---\nThe analysis has identified the best model for each store-product combination based on Mean Absolute Error (MAE).\nThe distribution of the best models is displayed above, showing which model performed best most frequently.\n\nBest Model Distribution (with percentages):\n+-----------------+-----+------------------+\n|best_model       |count|percentage        |\n+-----------------+-----+------------------+\n|XGBoost          |5049 |40.49891714125291 |\n|Baseline Mean    |3864 |30.993823694553623|\n|Linear Regression|3554 |28.50725916419347 |\n+-----------------+-----+------------------+\n\n\n--- Contextualizing MAE Values with Source Data Statistics ---\n\nDescriptive statistics for 'weekly_quantities_sold' from ARIMA model's source table (Machine_Learning.features.weekly_features_combos_with_data):\n+-------+----------------------+\n|summary|weekly_quantities_sold|\n+-------+----------------------+\n|  count|               2836449|\n|   mean|              4.381446|\n| stddev|    11.895019830668268|\n|    min|                  0.00|\n|    25%|                   1.0|\n|    50%|                   2.0|\n|    75%|                   4.0|\n|    max|               1801.00|\n+-------+----------------------+\n\n\n--- Contextualizing ARIMA's Mean MAE (0.534194) ---\n  Mean 'weekly_quantities_sold': 4.3814\n  Standard Deviation 'weekly_quantities_sold': 11.8950\n  Min 'weekly_quantities_sold': 0.0000\n  Max 'weekly_quantities_sold': 1801.0000\n  MAE as % of Mean Sales: 12.19%\n  MAE as % of Standard Deviation: 4.49%\n\n--- Additional ARIMA Metrics (Overall Average) ---\n  Average R2: 0.000000\n  Average Accuracy: 0.730183\n  (Note: The average Accuracy of 0.730183 for ARIMA (1 - MAPE) implies a very high percentage error, indicating potential issues with the MAPE calculation, especially for time series with zero or near-zero actuals.)\n"]}],"execution_count":20,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"advisor":{"adviceMetadata":"{\"artifactId\":\"f45820bd-93bd-4762-a7b1-acf43a300906\",\"activityId\":\"6e10dd3b-1cf4-4a85-8432-fdf3468ca7fe\",\"applicationId\":\"application_1751499584317_0001\",\"jobGroupId\":\"22\",\"advices\":{\"info\":1}}"}},"id":"11125c1d-0435-443b-bbe1-4035c747dcf2"},{"cell_type":"markdown","source":["## **Model Evaluation** - Products with no data "],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5fb6c492-8bbe-4207-8f3c-765b431852d9"},{"cell_type":"code","source":["### Section 1: Setup and Configuration\n","\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, lit, min, count, when\n","from pyspark.sql.window import Window\n","\n","\n","\n","baseline_table = \"Machine_Learning.results.results_baseline_mean\"\n","linear_regression_table = \"Machine_Learning.results.results_linear_regression_products_w_no_data\"\n","xgboost_table = \"Machine_Learning.results.results_xgboost_products_w_no_data\"\n","\n","print(f\"Table paths defined:\\n\"\n","      f\"  Baseline: {baseline_table}\\n\"\n","      f\"  Linear Regression: {linear_regression_table}\\n\"\n","      f\"  XGBoost: {xgboost_table}\")\n","\n","### Section 2: Load Data\n","# This section loads the necessary columns (store_key, product_key, mae) from each results table.\n","\n","print(\"\\n--- Loading Data ---\")\n","\n","# Load Baseline Mean results\n","try:\n","    df_baseline = spark.table(baseline_table).select(\n","        col(\"store_key\"),\n","        col(\"product_key\"),\n","        col(\"mae\").alias(\"mae_baseline\"),\n","        col(\"r2\").alias(\"r2_baseline\"),          # ADD THIS LINE\n","        col(\"accuracy\").alias(\"accuracy_baseline\") # ADD THIS LINE\n","    )\n","    print(f\"Loaded {df_baseline.count()} rows from Baseline table.\")\n","    print(\"Sample from df_baseline:\")\n","    df_baseline.show(5)\n","except Exception as e:\n","    print(f\"Error loading Baseline table '{baseline_table}': {e}\")\n","    # IMPORTANT: Update the schema for the empty DataFrame as well!\n","    df_baseline = spark.createDataFrame([], \"store_key:int, product_key:int, mae_baseline:double, r2_baseline:double, accuracy_baseline:double\")\n","\n","\n","# Load Linear Regression results\n","try:\n","    df_linear_reg = spark.table(linear_regression_table).select(\n","        col(\"store_key\"),\n","        col(\"product_key\"),\n","        col(\"mae\").alias(\"mae_linear_reg\"),\n","        col(\"r2\").alias(\"r2_linear_reg\"),          # ADD THIS LINE\n","        col(\"accuracy\").alias(\"accuracy_linear_reg\") # ADD THIS LINE\n","    )\n","    print(f\"Loaded {df_linear_reg.count()} rows from Linear Regression table.\")\n","    print(\"Sample from df_linear_reg:\")\n","    df_linear_reg.show(5)\n","except Exception as e:\n","    print(f\"Error loading Linear Regression table '{linear_regression_table}': {e}\")\n","    # IMPORTANT: Update the schema for the empty DataFrame as well!\n","    df_linear_reg = spark.createDataFrame([], \"store_key:int, product_key:int, mae_linear_reg:double, r2_linear_reg:double, accuracy_linear_reg:double\")\n","\n","\n","# Load XGBoost results\n","try:\n","    df_xgboost = spark.table(xgboost_table).select(\n","        col(\"store_key\"),\n","        col(\"product_key\"),\n","        col(\"mae\").alias(\"mae_xgboost\"),\n","        col(\"r2\").alias(\"r2_xgboost\"),          # ADD THIS LINE\n","        col(\"accuracy\").alias(\"accuracy_xgboost\") # ADD THIS LINE\n","    )\n","    print(f\"Loaded {df_xgboost.count()} rows from XGBoost table.\")\n","    print(\"Sample from df_xgboost:\")\n","    df_xgboost.show(5)\n","except Exception as e:\n","    print(f\"Error loading XGBoost table '{xgboost_table}': {e}\")\n","    # IMPORTANT: Update the schema for the empty DataFrame as well!\n","    df_xgboost = spark.createDataFrame([], \"store_key:int, product_key:int, mae_xgboost:double, r2_xgboost:double, accuracy_xgboost:double\")\n","\n","\n","\n","### Section 3: Join Data\n","# This section joins the loaded dataframes on `store_key` and `product_key` to consolidate MAE values.\n","\n","print(\"\\n--- Joining Data ---\")\n","\n","# Join all dataframes using full outer join to ensure all combinations are considered.\n","# Fill null MAE values with infinity so missing model results are not considered the \"best\".\n","df_joined = df_baseline.join(df_linear_reg, [\"store_key\", \"product_key\"], \"fullouter\") \\\n","                       .join(df_xgboost, [\"store_key\", \"product_key\"], \"fullouter\")\n","\n","print(f\"Initial joined dataframe has {df_joined.count()} rows.\")\n","\n","\n","# Handle potential nulls in MAE columns (e.g., if a model didn't have results for a specific combination)\n","# We fill with float('inf') so these combinations are not selected as the best.\n","df_joined = df_joined.fillna(float('inf'), subset=[\"mae_baseline\", \"mae_linear_reg\", \"mae_xgboost\"])\n","\n","\n","\n","### Section 4: Determine the Best Model for Each Combination\n","# This section identifies the model with the lowest MAE for every unique store-product pair.\n","\n","print(\"\\n--- Determining Best Model per Combination ---\")\n","\n","# Import the 'least' function if not already imported\n","from pyspark.sql.functions import least\n","\n","# Find the minimum MAE across all models for each combination using least()\n","# We don't need Window.partitionBy(\"store_key\", \"product_key\") here because least() operates row-wise.\n","df_with_min_mae = df_joined.withColumn(\"min_mae\",\n","                                       least(col(\"mae_baseline\"), col(\"mae_linear_reg\"), col(\"mae_xgboost\")))\n","\n","# Determine the best model based on the minimum MAE\n","df_best_model = df_with_min_mae.withColumn(\n","    \"best_model\",\n","    when(col(\"mae_baseline\") == col(\"min_mae\"), lit(\"Baseline Mean\"))\n","    .when(col(\"mae_linear_reg\") == col(\"min_mae\"), lit(\"Linear Regression\"))\n","    .when(col(\"mae_xgboost\") == col(\"min_mae\"), lit(\"XGBoost\"))\n","    .otherwise(lit(\"Undetermined_Error\")) # Should ideally not happen if all MAEs are handled\n",")\n","\n","print(\"Sample of determined best model for each combination:\")\n","df_best_model.show(10)\n","### Section 5: Count Best Model Occurrences\n","# This section counts how many times each model was selected as the best across all combinations.\n","\n","print(\"\\n--- Counting Best Model Occurrences ---\")\n","\n","# Count occurrences of each best model\n","best_model_counts = df_best_model.groupBy(\"best_model\").count().orderBy(col(\"count\").desc())\n","\n","print(\"Final count of best model selections:\")\n","best_model_counts.show(truncate=False)\n","\n","### Section 6: Conclusion and Summary\n","# This section provides a summary of the analysis.\n","\n","print(\"\\n--- Analysis Complete ---\")\n","print(\"The analysis has identified the best model for each store-product combination based on Mean Absolute Error (MAE).\")\n","print(\"The distribution of the best models is displayed above, showing which model performed best most frequently.\")\n","\n","# Optional: Calculate percentages\n","total_combinations = df_best_model.count()\n","if total_combinations > 0:\n","    best_model_percentages = best_model_counts.withColumn(\"percentage\", (col(\"count\") / total_combinations) * 100)\n","    print(\"\\nBest Model Distribution (with percentages):\")\n","    best_model_percentages.show(truncate=False)\n","else:\n","    print(\"\\nNo combinations found to analyze.\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":20,"statement_ids":[20],"state":"finished","livy_statement_state":"available","session_id":"6e10dd3b-1cf4-4a85-8432-fdf3468ca7fe","normalized_state":"finished","queued_time":"2025-07-03T00:22:00.9259763Z","session_start_time":null,"execution_start_time":"2025-07-03T00:22:00.9274053Z","execution_finish_time":"2025-07-03T00:22:08.0849088Z","parent_msg_id":"7448c37c-d448-4736-a7d3-c4a63a45a5a9"},"text/plain":"StatementMeta(, 6e10dd3b-1cf4-4a85-8432-fdf3468ca7fe, 20, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Table paths defined:\n  Baseline: Machine_Learning.results.results_baseline_mean\n  Linear Regression: Machine_Learning.results.results_linear_regression_products_w_no_data\n  XGBoost: Machine_Learning.results.results_xgboost_products_w_no_data\n\n--- Loading Data ---\nLoaded 12467 rows from Baseline table.\nSample from df_baseline:\n+---------+-----------+--------------------+-----------+------------------+\n|store_key|product_key|        mae_baseline|r2_baseline| accuracy_baseline|\n+---------+-----------+--------------------+-----------+------------------+\n|        1|         18|0.022805429864253046|        0.0|0.9928058580869864|\n|        1|         38| 0.07632107023411372|        0.0|0.9510762370294142|\n|        1|         44|0.002266187050359747|        0.0|0.9978209739900387|\n|        1|         61|0.023174061433446802|        0.0|0.9905024338387514|\n|        1|         68|  0.2788829787234044|        0.0|0.8605585106382978|\n+---------+-----------+--------------------+-----------+------------------+\nonly showing top 5 rows\n\nLoaded 12465 rows from Linear Regression table.\nSample from df_linear_reg:\n+---------+-----------+--------------------+-------------+-------------------+\n|store_key|product_key|      mae_linear_reg|r2_linear_reg|accuracy_linear_reg|\n+---------+-----------+--------------------+-------------+-------------------+\n|        1|         12|                 0.0|          1.0|                1.0|\n|        1|         21|  0.7305356136303374|          0.0| 0.6347321931848313|\n|        1|         28|0.013047858360085596|          0.0| 0.9758372993331749|\n|        1|         40|0.012282783892355376|          0.0| 0.9877172161076446|\n|        1|         45| 0.09261631481615229|          0.0| 0.9691278950612826|\n+---------+-----------+--------------------+-------------+-------------------+\nonly showing top 5 rows\n\nLoaded 12234 rows from XGBoost table.\nSample from df_xgboost:\n+---------+-----------+--------------------+----------+------------------+\n|store_key|product_key|         mae_xgboost|r2_xgboost|  accuracy_xgboost|\n+---------+-----------+--------------------+----------+------------------+\n|        1|         24|9.211587905884056E-4|       0.0|  0.99905035176228|\n|        1|         60| 0.02556312084197998|       0.0|  0.98721843957901|\n|        1|         66|2.335143089294833...|       0.0|0.9997186574591211|\n|        1|         71|6.765747070311967E-4|       0.0|0.9987918308803014|\n|        1|        134|0.019612669944763184|       0.0| 0.990835200960391|\n+---------+-----------+--------------------+----------+------------------+\nonly showing top 5 rows\n\n\n--- Joining Data ---\nInitial joined dataframe has 12467 rows.\n\n--- Determining Best Model per Combination ---\nSample of determined best model for each combination:\n+---------+-----------+--------------------+-----------+-------------------+--------------------+-------------+-------------------+--------------------+----------+------------------+--------------------+-----------------+\n|store_key|product_key|        mae_baseline|r2_baseline|  accuracy_baseline|      mae_linear_reg|r2_linear_reg|accuracy_linear_reg|         mae_xgboost|r2_xgboost|  accuracy_xgboost|             min_mae|       best_model|\n+---------+-----------+--------------------+-----------+-------------------+--------------------+-------------+-------------------+--------------------+----------+------------------+--------------------+-----------------+\n|        1|          2| 0.13866302864938618|        0.0| 0.9274015556809496|0.030766652545475504|          0.0| 0.9838918049500128| 0.05111983776092521|       0.0|0.9732356870361648|0.030766652545475504|Linear Regression|\n|        5|          2|  1.2386631016042782|        0.0| -2.440730837789662| 0.22297554844844703|          0.0| 0.3806234765320915| 0.21253071665763856|       0.0|0.4096368981732261| 0.21253071665763856|          XGBoost|\n|        6|          2|                 0.0|        1.0|                1.0|                 0.0|          1.0|                1.0|                 0.0|       1.0|               1.0|                 0.0|    Baseline Mean|\n|        8|          2|  0.2697124600638978|        0.0| 0.5718849840255591| 0.03212396978977616|          0.0| 0.9490095717622601|0.022110338211059566|       0.0|0.9649042250618102|0.022110338211059566|          XGBoost|\n|       10|          2|0.022586926286508824|        0.0| 0.9921024733263956|0.018899598811149998|          0.0| 0.9933917486674301|0.026490330696105957|       0.0|0.9907376466097532|0.018899598811149998|Linear Regression|\n|       12|          2| 0.13932506887052343|        0.0| 0.8606749311294766| 0.06336525780618918|          0.0| 0.9366347421938108| 0.09077057242393494|       0.0|0.9092294275760651| 0.06336525780618918|Linear Regression|\n|       13|          2|  2.1909195402298853|        0.0| 0.6348467432950191| 0.18140923774202022|          0.0| 0.9697651270429967| 0.16190576553344727|       0.0|0.9730157057444254| 0.16190576553344727|          XGBoost|\n|       19|          2| 0.08417355371900825|        0.0| 0.9423468810143779| 0.04269774449077568|          0.0|  0.970754969526866| 0.02122529506683346|       0.0|0.9854621266665524| 0.02122529506683346|          XGBoost|\n|       21|          2|  2.0948249027237353|        0.0|0.47629377431906617|  0.3014770521700254|          0.0| 0.9246307369574936|  0.5072191953659058|       0.0|0.8731952011585236|  0.3014770521700254|Linear Regression|\n|       23|          2|          0.33621875|        0.0| 0.6886863425925926| 0.09822642053984054|          0.0| 0.9090496106112588| 0.06814215898513787|       0.0|0.9369054083470946| 0.06814215898513787|          XGBoost|\n+---------+-----------+--------------------+-----------+-------------------+--------------------+-------------+-------------------+--------------------+----------+------------------+--------------------+-----------------+\nonly showing top 10 rows\n\n\n--- Counting Best Model Occurrences ---\nFinal count of best model selections:\n+-----------------+-----+\n|best_model       |count|\n+-----------------+-----+\n|XGBoost          |5049 |\n|Baseline Mean    |3864 |\n|Linear Regression|3554 |\n+-----------------+-----+\n\n\n--- Analysis Complete ---\nThe analysis has identified the best model for each store-product combination based on Mean Absolute Error (MAE).\nThe distribution of the best models is displayed above, showing which model performed best most frequently.\n\nBest Model Distribution (with percentages):\n+-----------------+-----+------------------+\n|best_model       |count|percentage        |\n+-----------------+-----+------------------+\n|XGBoost          |5049 |40.49891714125291 |\n|Baseline Mean    |3864 |30.993823694553623|\n|Linear Regression|3554 |28.50725916419347 |\n+-----------------+-----+------------------+\n\n"]}],"execution_count":18,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3f2a1903-fc7f-4bd8-93c6-5bb32f8d38ad"},{"cell_type":"code","source":["import numpy as np"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":14,"statement_ids":[14],"state":"finished","livy_statement_state":"available","session_id":"6e10dd3b-1cf4-4a85-8432-fdf3468ca7fe","normalized_state":"finished","queued_time":"2025-07-03T00:14:52.7664557Z","session_start_time":null,"execution_start_time":"2025-07-03T00:14:52.767568Z","execution_finish_time":"2025-07-03T00:14:53.2378168Z","parent_msg_id":"a26b8d86-cf71-4c1c-b7d0-b212a9d0a12d"},"text/plain":"StatementMeta(, 6e10dd3b-1cf4-4a85-8432-fdf3468ca7fe, 14, Finished, Available, Finished)"},"metadata":{}}],"execution_count":12,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"25c8bdac-c1fb-450d-946c-7bb271b79025"},{"cell_type":"code","source":["# --- Section 7: Average MAE for Each Model When Selected as Best ---\n","# This section calculates the average MAE for each model, considering only\n","# the combinations where that specific model was chosen as the best.\n","\n","print(\"\\n--- Average MAE for Each Model When Selected as Best ---\")\n","\n","# --- Baseline Mean ---\n","baseline_best_count = df_best_model.filter(col(\"best_model\") == \"Baseline Mean\").count()\n","if baseline_best_count > 0:\n","    avg_mae_baseline_when_best = df_best_model.filter(col(\"best_model\") == \"Baseline Mean\") \\\n","                                              .select(F.mean(\"mae_baseline\")) \\\n","                                              .collect()[0][0]\n","    print(f\"Average MAE for Baseline Mean (when selected as best, {baseline_best_count} times): {avg_mae_baseline_when_best:.6f}\")\n","else:\n","    avg_mae_baseline_when_best = np.nan\n","    print(\"Baseline Mean was never selected as the best model.\")\n","\n","\n","# --- Linear Regression ---\n","lr_best_count = df_best_model.filter(col(\"best_model\") == \"Linear Regression\").count()\n","if lr_best_count > 0:\n","    avg_mae_lr_when_best = df_best_model.filter(col(\"best_model\") == \"Linear Regression\") \\\n","                                        .select(F.mean(\"mae_linear_reg\")) \\\n","                                        .collect()[0][0]\n","    print(f\"Average MAE for Linear Regression (when selected as best, {lr_best_count} times): {avg_mae_lr_when_best:.6f}\")\n","else:\n","    avg_mae_lr_when_best = np.nan\n","    print(\"Linear Regression was never selected as the best model.\")\n","\n","\n","# --- XGBoost ---\n","xgb_best_count = df_best_model.filter(col(\"best_model\") == \"XGBoost\").count()\n","if xgb_best_count > 0:\n","    avg_mae_xgb_when_best = df_best_model.filter(col(\"best_model\") == \"XGBoost\") \\\n","                                         .select(F.mean(\"mae_xgboost\")) \\\n","                                         .collect()[0][0]\n","    print(f\"Average MAE for XGBoost (when selected as best, {xgb_best_count} times): {avg_mae_xgb_when_best:.6f}\")\n","else:\n","    avg_mae_xgb_when_best = np.nan\n","    print(\"XGBoost was never selected as the best model.\")\n","\n","\n","# --- ARIMA ---\n","arima_best_count = df_best_model.filter(col(\"best_model\") == \"ARIMA\").count()\n","if arima_best_count > 0:\n","    avg_mae_arima_when_best = df_best_model.filter(col(\"best_model\") == \"ARIMA\") \\\n","                                           .select(F.mean(\"mae_arima\")) \\\n","                                           .collect()[0][0]\n","    print(f\"Average MAE for ARIMA (when selected as best, {arima_best_count} times): {avg_mae_arima_when_best:.6f}\")\n","else:\n","    avg_mae_arima_when_best = np.nan\n","    print(\"ARIMA was never selected as the best model.\")\n","\n","\n","print(\"\\n--- Contextualizing These Specific MAEs with Source Data Statistics ---\")\n","\n","# --- First, get the descriptive statistics for the relevant source tables ---\n","\n","# For ARIMA (weekly_features_combos_with_data)\n","arima_features_table = \"Machine_Learning.features.weekly_features_combos_with_data\"\n","try:\n","    df_arima_features = spark.table(arima_features_table)\n","    arima_sales_stats = df_arima_features.select(\n","        F.mean(\"weekly_quantities_sold\").alias(\"mean_sales\"),\n","        F.stddev(\"weekly_quantities_sold\").alias(\"stddev_sales\"),\n","        F.min(\"weekly_quantities_sold\").alias(\"min_sales\"),\n","        F.max(\"weekly_quantities_sold\").alias(\"max_sales\")\n","    ).collect()[0]\n","    mean_sales_arima = arima_sales_stats[\"mean_sales\"]\n","    stddev_sales_arima = arima_sales_stats[\"stddev_sales\"]\n","except Exception as e:\n","    mean_sales_arima, stddev_sales_arima = None, None\n","    print(f\"Error getting stats for ARIMA source table '{arima_features_table}': {e}\")\n","\n","\n","# For Baseline, Linear Regression, XGBoost (weekly_features_combos_with_no_data)\n","other_models_features_table = \"Machine_Learning.features.weekly_features_combos_with_no_data\"\n","try:\n","    df_other_models_features = spark.table(other_models_features_table)\n","    other_sales_stats = df_other_models_features.select(\n","        F.mean(\"weekly_quantities_sold\").alias(\"mean_sales\"),\n","        F.stddev(\"weekly_quantities_sold\").alias(\"stddev_sales\"),\n","        F.min(\"weekly_quantities_sold\").alias(\"min_sales\"),\n","        F.max(\"weekly_quantities_sold\").alias(\"max_sales\")\n","    ).collect()[0]\n","    mean_sales_other = other_sales_stats[\"mean_sales\"]\n","    stddev_sales_other = other_sales_stats[\"stddev_sales\"]\n","except Exception as e:\n","    mean_sales_other, stddev_sales_other = None, None\n","    print(f\"Error getting stats for LR/XGBoost/Baseline source table '{other_models_features_table}': {e}\")\n","\n","\n","# --- Now contextualize each relevant MAE ---\n","\n","# Contextualize Baseline MAE\n","if avg_mae_baseline_when_best is not None and not np.isnan(avg_mae_baseline_when_best):\n","    print(f\"\\n--- Contextualizing Baseline Mean's MAE (when best): {avg_mae_baseline_when_best:.6f} ---\")\n","    if mean_sales_other is not None and float(mean_sales_other) != 0:\n","        print(f\"  MAE as % of Mean Sales: {(avg_mae_baseline_when_best / float(mean_sales_other) * 100):.2f}%\")\n","    if stddev_sales_other is not None and float(stddev_sales_other) != 0:\n","        print(f\"  MAE as % of Standard Deviation: {(avg_mae_baseline_when_best / float(stddev_sales_other) * 100):.2f}%\")\n","\n","# Contextualize Linear Regression MAE\n","if avg_mae_lr_when_best is not None and not np.isnan(avg_mae_lr_when_best):\n","    print(f\"\\n--- Contextualizing Linear Regression's MAE (when best): {avg_mae_lr_when_best:.6f} ---\")\n","    if mean_sales_other is not None and float(mean_sales_other) != 0:\n","        print(f\"  MAE as % of Mean Sales: {(avg_mae_lr_when_best / float(mean_sales_other) * 100):.2f}%\")\n","    if stddev_sales_other is not None and float(stddev_sales_other) != 0:\n","        print(f\"  MAE as % of Standard Deviation: {(avg_mae_lr_when_best / float(stddev_sales_other) * 100):.2f}%\")\n","\n","# Contextualize XGBoost MAE\n","if avg_mae_xgb_when_best is not None and not np.isnan(avg_mae_xgb_when_best):\n","    print(f\"\\n--- Contextualizing XGBoost's MAE (when best): {avg_mae_xgb_when_best:.6f} ---\")\n","    if mean_sales_other is not None and float(mean_sales_other) != 0:\n","        print(f\"  MAE as % of Mean Sales: {(avg_mae_xgb_when_best / float(mean_sales_other) * 100):.2f}%\")\n","    if stddev_sales_other is not None and float(stddev_sales_other) != 0:\n","        print(f\"  MAE as % of Standard Deviation: {(avg_mae_xgb_when_best / float(stddev_sales_other) * 100):.2f}%\")\n","\n","# Contextualize ARIMA MAE\n","if avg_mae_arima_when_best is not None and not np.isnan(avg_mae_arima_when_best):\n","    print(f\"\\n--- Contextualizing ARIMA's MAE (when best): {avg_mae_arima_when_best:.6f} ---\")\n","    if mean_sales_arima is not None and float(mean_sales_arima) != 0:\n","        print(f\"  MAE as % of Mean Sales: {(avg_mae_arima_when_best / float(mean_sales_arima) * 100):.2f}%\")\n","    if stddev_sales_arima is not None and float(stddev_arima_sales) != 0: # Corrected variable name from stddev_arima_sales\n","        print(f\"  MAE as % of Standard Deviation: {(avg_mae_arima_when_best / float(stddev_sales_arima) * 100):.2f}%\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":17,"statement_ids":[17],"state":"finished","livy_statement_state":"available","session_id":"6e10dd3b-1cf4-4a85-8432-fdf3468ca7fe","normalized_state":"finished","queued_time":"2025-07-03T00:16:20.9844856Z","session_start_time":null,"execution_start_time":"2025-07-03T00:16:20.9859366Z","execution_finish_time":"2025-07-03T00:16:27.8217332Z","parent_msg_id":"bcdc7a7e-a2f2-4ada-9564-daebe6f365c3"},"text/plain":"StatementMeta(, 6e10dd3b-1cf4-4a85-8432-fdf3468ca7fe, 17, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n--- Average MAE for Each Model When Selected as Best ---\nAverage MAE for Baseline Mean (when selected as best, 3864 times): 0.012532\nAverage MAE for Linear Regression (when selected as best, 3554 times): 0.195571\nAverage MAE for XGBoost (when selected as best, 5049 times): 0.061120\nARIMA was never selected as the best model.\n\n--- Contextualizing These Specific MAEs with Source Data Statistics ---\n\n--- Contextualizing Baseline Mean's MAE (when best): 0.012532 ---\n  MAE as % of Mean Sales: 0.36%\n  MAE as % of Standard Deviation: 0.10%\n\n--- Contextualizing Linear Regression's MAE (when best): 0.195571 ---\n  MAE as % of Mean Sales: 5.67%\n  MAE as % of Standard Deviation: 1.55%\n\n--- Contextualizing XGBoost's MAE (when best): 0.061120 ---\n  MAE as % of Mean Sales: 1.77%\n  MAE as % of Standard Deviation: 0.48%\n"]}],"execution_count":15,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6a755d33-a9fb-4103-b04d-c810af0d309d"},{"cell_type":"code","source":["print(\"\\n--- Average R2 and Accuracy for Each Model When Selected as Best ---\")\n","\n","# --- Baseline Mean ---\n","baseline_best_df = df_best_model.filter(col(\"best_model\") == \"Baseline Mean\")\n","if baseline_best_df.count() > 0:\n","    avg_r2_baseline_when_best = baseline_best_df.select(F.mean(\"r2_baseline\")).collect()[0][0]\n","    avg_acc_baseline_when_best = baseline_best_df.select(F.mean(\"accuracy_baseline\")).collect()[0][0]\n","    print(f\"Average R2 for Baseline Mean (when best): {avg_r2_baseline_when_best:.6f}\")\n","    print(f\"Average Accuracy for Baseline Mean (when best): {avg_acc_baseline_when_best:.6f}\")\n","else:\n","    print(\"Baseline Mean was never selected as the best model, no R2/Accuracy to report.\")\n","\n","\n","# --- Linear Regression ---\n","lr_best_df = df_best_model.filter(col(\"best_model\") == \"Linear Regression\")\n","if lr_best_df.count() > 0:\n","    avg_r2_lr_when_best = lr_best_df.select(F.mean(\"r2_linear_reg\")).collect()[0][0]\n","    avg_acc_lr_when_best = lr_best_df.select(F.mean(\"accuracy_linear_reg\")).collect()[0][0]\n","    print(f\"Average R2 for Linear Regression (when best): {avg_r2_lr_when_best:.6f}\")\n","    print(f\"Average Accuracy for Linear Regression (when best): {avg_acc_lr_when_best:.6f}\")\n","else:\n","    print(\"Linear Regression was never selected as the best model, no R2/Accuracy to report.\")\n","\n","\n","# --- XGBoost ---\n","xgb_best_df = df_best_model.filter(col(\"best_model\") == \"XGBoost\")\n","if xgb_best_df.count() > 0:\n","    avg_r2_xgb_when_best = xgb_best_df.select(F.mean(\"r2_xgboost\")).collect()[0][0]\n","    avg_acc_xgb_when_best = xgb_best_df.select(F.mean(\"accuracy_xgboost\")).collect()[0][0]\n","    print(f\"Average R2 for XGBoost (when best): {avg_r2_xgb_when_best:.6f}\")\n","    print(f\"Average Accuracy for XGBoost (when best): {avg_acc_xgb_when_best:.6f}\")\n","else:\n","    print(\"XGBoost was never selected as the best model, no R2/Accuracy to report.\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":21,"statement_ids":[21],"state":"finished","livy_statement_state":"available","session_id":"6e10dd3b-1cf4-4a85-8432-fdf3468ca7fe","normalized_state":"finished","queued_time":"2025-07-03T00:22:13.634186Z","session_start_time":null,"execution_start_time":"2025-07-03T00:22:13.6355876Z","execution_finish_time":"2025-07-03T00:22:22.2228214Z","parent_msg_id":"ac9e7aaf-39d3-4440-915f-69b1d1fd10bf"},"text/plain":"StatementMeta(, 6e10dd3b-1cf4-4a85-8432-fdf3468ca7fe, 21, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n--- Average R2 and Accuracy for Each Model When Selected as Best ---\nAverage R2 for Baseline Mean (when best): 0.113645\nAverage Accuracy for Baseline Mean (when best): -821259.943450\nAverage R2 for Linear Regression (when best): 0.033250\nAverage Accuracy for Linear Regression (when best): -783925.996209\nAverage R2 for XGBoost (when best): -0.001791\nAverage Accuracy for XGBoost (when best): -324990.710337\n"]}],"execution_count":19,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"94e9ae87-e710-4c48-a743-788fb8484da5"},{"cell_type":"markdown","source":[],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"30323e58-fe24-48d1-a4f5-aff385c36dce"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"798eb282-038c-4a0e-bb1f-e1c57f0083f2"}],"default_lakehouse":"798eb282-038c-4a0e-bb1f-e1c57f0083f2","default_lakehouse_name":"Machine_Learning","default_lakehouse_workspace_id":"7dc535a0-d10f-45d2-a704-6132306d730d"}}},"nbformat":4,"nbformat_minor":5}