{"cells":[{"cell_type":"code","source":["df_date = spark.sql(\"SELECT * FROM Gold_Data.dim_date.dim_date \")\n","df_product = spark.sql(\"SELECT * FROM Gold_Data.dim_product.dim_product \")\n","df_promotion = spark.sql(\"SELECT * FROM Gold_Data.dim_promotion.dim_promotion \")\n","df_stores = spark.sql(\"SELECT * FROM Gold_Data.dim_stores.dim_stores\")\n","df_sales = spark.sql(\"SELECT * FROM Gold_Data.fact_sales.fact_sales \")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"81137864-50c0-4cbb-ad67-823f0acfc3a0","normalized_state":"finished","queued_time":"2025-07-07T12:15:19.017634Z","session_start_time":"2025-07-07T12:15:19.0184967Z","execution_start_time":"2025-07-07T12:15:32.0721347Z","execution_finish_time":"2025-07-07T12:15:50.7881837Z","parent_msg_id":"6160ea94-b035-4177-8491-275dce5f72a3"},"text/plain":"StatementMeta(, 81137864-50c0-4cbb-ad67-823f0acfc3a0, 3, Finished, Available, Finished)"},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9173debe-044d-46d3-8aae-ddc1125141b5"},{"cell_type":"code","source":["df_date.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"Business_Intelligence_Data.dim_date.dim_date\")\n","df_product.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"Business_Intelligence_Data.dim_product.dim_product\")\n","df_promotion.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"Business_Intelligence_Data.dim_promotion.dim_promotion\")\n","df_stores.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"Business_Intelligence_Data.dim_stores.dim_stores\")\n","df_sales.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"Business_Intelligence_Data.fact_sales.fact_sales\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"81137864-50c0-4cbb-ad67-823f0acfc3a0","normalized_state":"finished","queued_time":"2025-07-07T12:16:38.8733764Z","session_start_time":null,"execution_start_time":"2025-07-07T12:16:38.8744987Z","execution_finish_time":"2025-07-07T12:16:42.5358941Z","parent_msg_id":"4fbff9ad-15f8-459f-9da5-d36e13381a20"},"text/plain":"StatementMeta(, 81137864-50c0-4cbb-ad67-823f0acfc3a0, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"error","ename":"AnalysisException","evalue":"[_LEGACY_ERROR_TEMP_DELTA_0007] A schema mismatch detected when writing to the Delta table (Table ID: 9603bc76-8471-4e52-bf4a-074dcf5e82a2).\nTo enable schema migration using DataFrameWriter or DataStreamWriter, please set:\n'.option(\"mergeSchema\", \"true\")'.\nFor other operations, set the session configuration\nspark.databricks.delta.schema.autoMerge.enabled to \"true\". See the documentation\nspecific to the operation for details.\n\nTable schema:\nroot\n-- date_id: integer (nullable = true)\n-- full_date: date (nullable = true)\n-- day_of_week: integer (nullable = true)\n-- day_name: string (nullable = true)\n-- day_of_month: integer (nullable = true)\n-- day_of_year: integer (nullable = true)\n-- week_of_year: integer (nullable = true)\n-- month: integer (nullable = true)\n-- month_name: string (nullable = true)\n-- quarter: integer (nullable = true)\n-- year: integer (nullable = true)\n-- is_weekend: boolean (nullable = true)\n-- is_holiday: boolean (nullable = true)\n-- business_day_offset_5_date: date (nullable = true)\n-- week_start_date: date (nullable = true)\n-- week_end_date: date (nullable = true)\n\n\nData schema:\nroot\n-- date_id: integer (nullable = true)\n-- full_date: date (nullable = true)\n-- day_of_week: integer (nullable = true)\n-- day_name: string (nullable = true)\n-- day_of_month: integer (nullable = true)\n-- day_of_year: integer (nullable = true)\n-- week_of_year: integer (nullable = true)\n-- month: integer (nullable = true)\n-- month_name: string (nullable = true)\n-- quarter: integer (nullable = true)\n-- year: integer (nullable = true)\n-- is_weekend: boolean (nullable = true)\n-- is_holiday: boolean (nullable = true)\n-- business_day_offset_5_date: date (nullable = true)\n-- week_start_date: date (nullable = true)\n-- week_end_date: date (nullable = true)\n-- num_holidays_in_week: integer (nullable = true)\n-- has_holiday_in_week: boolean (nullable = true)\n-- num_weekend_days_in_week: integer (nullable = true)\n\n         \nTo overwrite your schema or change partitioning, please set:\n'.option(\"overwriteSchema\", \"true\")'.\n\nNote that the schema can't be overwritten when using\n'replaceWhere'.\n         ","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_date\u001b[38;5;241m.\u001b[39mwrite\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msaveAsTable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBusiness_Intelligence_Data.dim_date.dim_date\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m df_product\u001b[38;5;241m.\u001b[39mwrite\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msaveAsTable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBusiness_Intelligence_Data.dim_product.dim_product\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m df_promotion\u001b[38;5;241m.\u001b[39mwrite\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msaveAsTable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBusiness_Intelligence_Data.dim_promotion.dim_promotion\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py:1586\u001b[0m, in \u001b[0;36mDataFrameWriter.saveAsTable\u001b[0;34m(self, name, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m   1584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1585\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m-> 1586\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msaveAsTable(name)\n","File \u001b[0;32m~/cluster-env/trident_env/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n","File \u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n","\u001b[0;31mAnalysisException\u001b[0m: [_LEGACY_ERROR_TEMP_DELTA_0007] A schema mismatch detected when writing to the Delta table (Table ID: 9603bc76-8471-4e52-bf4a-074dcf5e82a2).\nTo enable schema migration using DataFrameWriter or DataStreamWriter, please set:\n'.option(\"mergeSchema\", \"true\")'.\nFor other operations, set the session configuration\nspark.databricks.delta.schema.autoMerge.enabled to \"true\". See the documentation\nspecific to the operation for details.\n\nTable schema:\nroot\n-- date_id: integer (nullable = true)\n-- full_date: date (nullable = true)\n-- day_of_week: integer (nullable = true)\n-- day_name: string (nullable = true)\n-- day_of_month: integer (nullable = true)\n-- day_of_year: integer (nullable = true)\n-- week_of_year: integer (nullable = true)\n-- month: integer (nullable = true)\n-- month_name: string (nullable = true)\n-- quarter: integer (nullable = true)\n-- year: integer (nullable = true)\n-- is_weekend: boolean (nullable = true)\n-- is_holiday: boolean (nullable = true)\n-- business_day_offset_5_date: date (nullable = true)\n-- week_start_date: date (nullable = true)\n-- week_end_date: date (nullable = true)\n\n\nData schema:\nroot\n-- date_id: integer (nullable = true)\n-- full_date: date (nullable = true)\n-- day_of_week: integer (nullable = true)\n-- day_name: string (nullable = true)\n-- day_of_month: integer (nullable = true)\n-- day_of_year: integer (nullable = true)\n-- week_of_year: integer (nullable = true)\n-- month: integer (nullable = true)\n-- month_name: string (nullable = true)\n-- quarter: integer (nullable = true)\n-- year: integer (nullable = true)\n-- is_weekend: boolean (nullable = true)\n-- is_holiday: boolean (nullable = true)\n-- business_day_offset_5_date: date (nullable = true)\n-- week_start_date: date (nullable = true)\n-- week_end_date: date (nullable = true)\n-- num_holidays_in_week: integer (nullable = true)\n-- has_holiday_in_week: boolean (nullable = true)\n-- num_weekend_days_in_week: integer (nullable = true)\n\n         \nTo overwrite your schema or change partitioning, please set:\n'.option(\"overwriteSchema\", \"true\")'.\n\nNote that the schema can't be overwritten when using\n'replaceWhere'.\n         "]}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"faf4d518-a9a0-4a4f-bf54-e737c141c740"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"8b199459-5e89-4089-9cb9-de57033b37a0"},{"id":"80c09e50-4894-4c94-95b8-82d29d71f86a"}],"default_lakehouse":"8b199459-5e89-4089-9cb9-de57033b37a0","default_lakehouse_name":"Business_Intelligence_Data","default_lakehouse_workspace_id":"7dc535a0-d10f-45d2-a704-6132306d730d"}}},"nbformat":4,"nbformat_minor":5}