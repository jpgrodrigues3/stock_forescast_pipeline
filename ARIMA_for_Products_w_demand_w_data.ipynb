{"cells":[{"cell_type":"code","source":["%pip install --quiet pmdarima scikit-learn statsmodels numpy pandas mlflow"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[3,4,5,6],"state":"cancelled","livy_statement_state":null,"session_id":"e042e62f-599c-4423-a574-c96f03e04e95","normalized_state":"cancelled","queued_time":"2025-06-20T20:05:52.7119846Z","session_start_time":"2025-06-20T20:05:52.7123016Z","execution_start_time":"2025-06-20T20:06:05.5304228Z","execution_finish_time":"2025-06-20T20:06:13.4258805Z","parent_msg_id":"1f31fd60-269f-4051-8eab-7fca134a6868"},"text/plain":"StatementMeta(, e042e62f-599c-4423-a574-c96f03e04e95, 6, Cancelled, , Cancelled)"},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c6949f61-5ec4-4a5e-a7e9-025ac0bdb911"},{"cell_type":"code","source":["# ─────────────────────────────────────────────────────────────────────────────\n","# 0. LIBRARIES\n","# ─────────────────────────────────────────────────────────────────────────────\n","from pyspark.sql import functions as F, types as T\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import pandas_udf, PandasUDFType\n","from pyspark.sql.types import DoubleType, StringType, StructField, StructType, IntegerType\n","import pandas as pd\n","import numpy as np\n","import warnings\n","\n","from pmdarima import auto_arima\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","\n","import mlflow\n","import mlflow.pmdarima # Required for logging pmdarima models\n","from mlflow.models import infer_signature\n","from mlflow.pyfunc import PythonModel\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"state":"finished","livy_statement_state":"available","session_id":"617ff04b-c95e-41ea-b8e0-1024a6f4188e","normalized_state":"finished","queued_time":"2025-06-19T14:29:16.739116Z","session_start_time":null,"execution_start_time":"2025-06-19T14:29:56.3707408Z","execution_finish_time":"2025-06-19T14:30:29.9626237Z","parent_msg_id":"5e3b98a3-599e-4986-84a4-5a273bf21b83"},"text/plain":"StatementMeta(, 617ff04b-c95e-41ea-b8e0-1024a6f4188e, 9, Finished, Available, Finished)"},"metadata":{}}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"33ed1b86-144f-4c73-84fd-b3380d9a3467"},{"cell_type":"code","source":["# Initialize SparkSession if not already initialized (typical in a Fabric notebook\n","spark = SparkSession.builder.appName(\"ARIMAModelDeployment\").getOrCreate()\n","\n","# Configure MLflow tracking URI for Fabric\n","# This ensures MLflow logs to your Fabric workspace.\n","mlflow.set_tracking_uri(\"mlflow\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"19cb4a4c-921c-4cff-aa43-c13775768c1f"},{"cell_type":"code","source":["# ─────────────────────────────────────────────────────────────────────────────\n","# 1. LOAD WEEKLY DATA\n","# ─────────────────────────────────────────────────────────────────────────────\n","\n","df = spark.sql(\"\"\"\n","    SELECT *\n","    FROM Machine_Learning.filtered_data.all_year_fact_sales_demand_w_data\n","\"\"\")\n","\n","# We only need the three fields for modelling & evaluation\n","df_model = (\n","    df.select(\"product_key\", \"store_key\", \"week_start\", \"weekly_quantities_sold\")\n","      .orderBy(\"product_key\", \"store_key\", \"week_start\")\n",")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2498e0e5-0bd7-4987-965b-f8515a0e861f"},{"cell_type":"code","source":["# ─────────────────────────────────────────────────────────────────────────────\n","# 2. DEFINE GROUPED PANDAS-UDF FOR AUTO-ARIMA + METRICS + MLflow Logging\n","# ─────────────────────────────────────────────────────────────────────────────\n","result_schema = StructType([\n","    StructField(\"product_key\"       , IntegerType() , False),\n","    StructField(\"store_key\"         , IntegerType() , False),\n","    StructField(\"n_obs\"             , IntegerType() , False),\n","    StructField(\"aic\"               , DoubleType()  , True),\n","    StructField(\"bic\"               , DoubleType()  , True),\n","    StructField(\"arima_order\"       , StringType()  , True),\n","    StructField(\"seasonal_order\"    , StringType()  , True),\n","    StructField(\"mae\"               , DoubleType()  , True),\n","    StructField(\"rmse\"              , DoubleType()  , True),\n","    StructField(\"mape\"              , DoubleType()  , True),\n","    StructField(\"mlflow_run_id\"     , StringType()  , True), # Add MLflow run ID to schema\n","    StructField(\"model_uri\"         , StringType()  , True), # Add model URI to schema\n","])\n","\n","FORECAST_HORIZON = 4 # last 4 weeks -> test set\n","MIN_SERIES_LEN   = 99"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7a3456c3-fcb0-4c64-ae67-003359308fab"},{"cell_type":"code","source":["@pandas_udf(result_schema, PandasUDFType.GROUPED_MAP)  \n","def arima_per_pair(pdf: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    Receives one product-store history as a Pandas DataFrame,\n","    fits an auto_arima model, calculates metrics, and logs the model\n","    and metrics to MLflow.\n","    Returns a single-row Pandas DataFrame with metrics and MLflow info.\n","    \"\"\"\n","    product_key = int(pdf[\"product_key\"].iloc[0])\n","    store_key   = int(pdf[\"store_key\"].iloc[0])\n","\n","    # Ensure ordered by week\n","    pdf = pdf.sort_values(\"week_start\")\n","    y   = pdf[\"weekly_quantities_sold\"].fillna(0).astype(float).values\n","    n   = len(y)\n","\n","    # Default output (in case model cannot be fit or series is too short)\n","    out = {\n","        \"product_key\"   : product_key,\n","        \"store_key\"     : store_key,\n","        \"n_obs\"         : n,\n","        \"aic\"           : None,\n","        \"bic\"           : None,\n","        \"arima_order\"   : None,\n","        \"seasonal_order\": None,\n","        \"mae\"           : None,\n","        \"rmse\"          : None,\n","        \"mape\"          : None,\n","        \"mlflow_run_id\" : None,\n","        \"model_uri\"     : None,\n","    }\n","\n","    if n < max(MIN_SERIES_LEN, FORECAST_HORIZON + 2):\n","        warnings.warn(f\"Series too short ({n} obs) for product_key={product_key}, store_key={store_key}. No ARIMA fitted.\")\n","        return pd.DataFrame([out])\n","\n","    train, test = y[:-FORECAST_HORIZON], y[-FORECAST_HORIZON:]\n","\n","    # Start an MLflow run for each product-store pair\n","    with mlflow.start_run(nested=True, run_name=f\"ARIMA_Product_{product_key}_Store_{store_key}\") as run:\n","        try:\n","            model = auto_arima(\n","                train,\n","                seasonal=True,\n","                m=52,                   # weekly seasonality (change if needed)\n","                stepwise=True,\n","                suppress_warnings=True,\n","                error_action=\"ignore\",\n","                max_p=3, max_q=3, max_P=1, max_Q=1,\n","                max_order=5\n","            )\n","\n","            fcst = model.predict(n_periods=FORECAST_HORIZON)\n","            mae  = mean_absolute_error(test, fcst)\n","            rmse = np.sqrt(mean_squared_error(test, fcst))\n","            mape = np.mean(np.abs((test - fcst) / np.where(test == 0, np.nan, test))) * 100\n","\n","            # Log metrics to MLflow\n","            mlflow.log_metrics({\n","                \"aic\": float(model.aic()),\n","                \"bic\": float(model.bic()),\n","                \"mae\": float(mae),\n","                \"rmse\": float(rmse),\n","                \"mape\": float(mape),\n","            })\n","            \n","            # Log parameters to MLflow\n","            mlflow.log_params({\n","                \"arima_order\": str(model.order),\n","                \"seasonal_order\": str(model.seasonal_order),\n","                \"forecast_horizon\": FORECAST_HORIZON,\n","                \"min_series_len\": MIN_SERIES_LEN,\n","                \"product_key\": product_key, # Log product_key and store_key as params\n","                \"store_key\": store_key,\n","                \"n_obs_train\": len(train),\n","            })\n","\n","            # Log the pmdarima model\n","            signature = infer_signature(pd.Series(train), model.predict(n_periods=FORECAST_HORIZON))\n","            \n","            # Log the model under a specific artifact path\n","            mlflow.pmdarima.log_model(\n","                pmdarima_model=model,\n","                artifact_path=\"arima_model\",\n","                signature=signature,\n","                input_example=pd.Series(train[-10:]), # Example input for inference\n","                registered_model_name=f\"ARIMA_Product_{product_key}_Store_{store_key}_Model\" # Register model with a specific name\n","            )\n","            \n","            # Update output with MLflow run ID and model URI\n","            out.update({\n","                \"aic\"           : float(model.aic()),\n","                \"bic\"           : float(model.bic()),\n","                \"arima_order\"   : str(model.order),\n","                \"seasonal_order\": str(model.seasonal_order),\n","                \"mae\"           : float(mae),\n","                \"rmse\"          : float(rmse),\n","                \"mape\"          : float(mape),\n","                \"mlflow_run_id\" : run.info.run_id,\n","                \"model_uri\"     : f\"runs:/{run.info.run_id}/arima_model\",\n","            })\n","\n","        except Exception as e:\n","            warnings.warn(f\"auto_arima failed for ({product_key},{store_key}): {e}. Check MLflow run details.\")\n","            mlflow.log_param(\"status\", \"failed\") # Log failure status\n","            mlflow.log_param(\"error_message\", str(e))\n","            # If anything goes wrong, keep NaNs (already set)\n","\n","    return pd.DataFrame([out])"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":-1,"statement_ids":null,"state":"cancelled","livy_statement_state":null,"session_id":"617ff04b-c95e-41ea-b8e0-1024a6f4188e","normalized_state":"cancelled","queued_time":"2025-06-19T14:29:17.9075409Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2025-06-19T14:30:31.914309Z","parent_msg_id":"af87a326-6608-4717-a887-2836cd559ed3"},"text/plain":"StatementMeta(, 617ff04b-c95e-41ea-b8e0-1024a6f4188e, -1, Cancelled, , Cancelled)"},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a6703e31-9b4b-48c6-9164-cafda79ad116"},{"cell_type":"code","source":["# ─────────────────────────────────────────────────────────────────────────────\n","# 3. RUN THE UDF AND COLLECT METRICS AND MLFLOW INFO\n","# ─────────────────────────────────────────────────────────────────────────────\n","# This will trigger the training and MLflow logging for each product-store pair.\n","print(\"Starting ARIMA model training and MLflow logging for all product-store pairs...\")\n","metrics_and_mlflow_info_df = (\n","    df_model\n","        .groupBy(\"product_key\", \"store_key\")\n","        .apply(arima_per_pair)\n",")\n","\n","print(\"ARIMA model training and MLflow logging complete.\")\n","print(\"Showing results and MLflow run IDs:\")\n","metrics_and_mlflow_info_df.orderBy(\"mape\").show(20, truncate=False)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":-1,"statement_ids":null,"state":"cancelled","livy_statement_state":null,"session_id":"617ff04b-c95e-41ea-b8e0-1024a6f4188e","normalized_state":"cancelled","queued_time":"2025-06-19T14:29:18.0204253Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2025-06-19T14:30:31.9148082Z","parent_msg_id":"7a4e2e4f-3102-497d-addb-79b1d502a4e6"},"text/plain":"StatementMeta(, 617ff04b-c95e-41ea-b8e0-1024a6f4188e, -1, Cancelled, , Cancelled)"},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ebce2f3f-528f-4097-a89c-5209216bb193"},{"cell_type":"markdown","source":["# If needed experiment with Single Product-Store Combination"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e42b22c2-f684-4610-a186-3c3be2e8dc1c"},{"cell_type":"markdown","source":["## **Single Run**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"54234b84-8066-46ef-900e-4191f1483b54"},{"cell_type":"code","source":["def arima_single_pair(\n","        spark_df,\n","        product_key: int,\n","        store_key: int,\n","        forecast_horizon: int = 4,\n","        seasonal: bool = True,\n","        seasonal_periods: int = 52,\n","        min_series_len: int = 10,\n","    ) -> pd.DataFrame:\n","    \"\"\"\n","    Fit an auto_arima model for one product–store combination and\n","    return MAE/RMSE/MAPE + model orders.\n","\n","    Parameters\n","    ----------\n","    spark_df : DataFrame\n","        Weekly-granular Spark DataFrame with columns\n","        ['product_key','store_key','week_start','weekly_quantities_sold'].\n","    product_key, store_key : int\n","        Keys identifying the series to analyse.\n","    forecast_horizon : int, default 4\n","        Number of latest observations to hold out for accuracy metrics.\n","    seasonal : bool, default True\n","        Whether to let auto_arima search seasonal terms.\n","    seasonal_periods : int, default 52\n","        'm' parameter in SARIMA (52 = annual seasonality on weekly data).\n","    min_series_len : int, default 10\n","        Skip modelling if the series is shorter than this.\n","\n","    Returns\n","    -------\n","    pandas.DataFrame (one row)\n","    \"\"\"\n","    # ── 1. Pull history for that pair ───────────────────────────────────────\n","    pdf = (\n","        spark_df\n","        .filter(\n","            (F.col(\"product_key\") == product_key) &\n","            (F.col(\"store_key\")   == store_key)\n","        )\n","        .select(\"week_start\", \"weekly_quantities_sold\")\n","        .orderBy(\"week_start\")\n","        .toPandas()\n","    )\n","\n","    n_obs = len(pdf)\n","    if n_obs == 0:\n","        raise ValueError(f\"No data found for product_key={product_key}, store_key={store_key}\")\n","\n","    pdf[\"weekly_quantities_sold\"] = pdf[\"weekly_quantities_sold\"].fillna(0).astype(float)\n","    y = pdf[\"weekly_quantities_sold\"].values\n","\n","    # ── 2. Default output skeleton ─────────────────────────────────────────\n","    result = {\n","        \"product_key\"   : product_key,\n","        \"store_key\"     : store_key,\n","        \"n_obs\"         : n_obs,\n","        \"aic\"           : np.nan,\n","        \"bic\"           : np.nan,\n","        \"arima_order\"   : None,\n","        \"seasonal_order\": None,\n","        \"mae\"           : np.nan,\n","        \"rmse\"          : np.nan,\n","        \"mape\"          : np.nan,\n","    }\n","\n","    # ── 3. Skip very short series ──────────────────────────────────────────\n","    if n_obs < max(min_series_len, forecast_horizon + 2):\n","        warnings.warn(f\"Series too short ({n_obs} obs). No ARIMA fitted.\")\n","        return pd.DataFrame([result])\n","\n","    # ── 4. Train / test split ──────────────────────────────────────────────\n","    train, test = y[:-forecast_horizon], y[-forecast_horizon:]\n","\n","    try:\n","        # ── 5. Fit auto_arima ──────────────────────────────────────────────\n","        model = auto_arima(\n","            train,\n","            seasonal=seasonal,\n","            m=seasonal_periods if seasonal else 1,\n","            stepwise=True,\n","            suppress_warnings=True,\n","            error_action=\"ignore\",\n","            max_p=3, max_q=3, max_P=1, max_Q=1,\n","            max_order=5\n","        )\n","\n","        fcst = model.predict(n_periods=forecast_horizon)\n","\n","        # ── 6. Metrics ─────────────────────────────────────────────────────\n","        mae  = mean_absolute_error(test, fcst)\n","        rmse = np.sqrt(mean_squared_error(test, fcst))\n","        mape = np.mean(\n","            np.abs((test - fcst) / np.where(test == 0, np.nan, test))\n","        ) * 100\n","\n","        # ── 7. Populate result dict ───────────────────────────────────────\n","        result.update({\n","            \"aic\"           : float(model.aic()),\n","            \"bic\"           : float(model.bic()),\n","            \"arima_order\"   : str(model.order),\n","            \"seasonal_order\": str(model.seasonal_order),\n","            \"mae\"           : float(mae),\n","            \"rmse\"          : float(rmse),\n","            \"mape\"          : float(mape),\n","        })\n","\n","    except Exception as e:\n","        warnings.warn(f\"auto_arima failed for ({product_key},{store_key}): {e}\")\n","\n","    return pd.DataFrame([result])"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":-1,"statement_ids":null,"state":"cancelled","livy_statement_state":null,"session_id":"617ff04b-c95e-41ea-b8e0-1024a6f4188e","normalized_state":"cancelled","queued_time":"2025-06-19T14:29:17.4823138Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2025-06-19T14:30:31.9132586Z","parent_msg_id":"a363fb20-fa5d-47ba-8d75-ac0f91ddc6da"},"text/plain":"StatementMeta(, 617ff04b-c95e-41ea-b8e0-1024a6f4188e, -1, Cancelled, , Cancelled)"},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c1d04c08-bb9d-4a97-9006-b0ecfdc346fc"},{"cell_type":"code","source":["# df.show(5)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":-1,"statement_ids":null,"state":"cancelled","livy_statement_state":null,"session_id":"617ff04b-c95e-41ea-b8e0-1024a6f4188e","normalized_state":"cancelled","queued_time":"2025-06-19T14:29:17.5645717Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2025-06-19T14:30:31.9135752Z","parent_msg_id":"d0052992-f254-42f5-b0c7-035f51f96684"},"text/plain":"StatementMeta(, 617ff04b-c95e-41ea-b8e0-1024a6f4188e, -1, Cancelled, , Cancelled)"},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e81cc44d-f50d-4a62-9973-97c50affed50"},{"cell_type":"code","source":["# sample_product = 468\n","# sample_store   = 46\n","\n","# metrics_pdf = arima_single_pair(\n","#     df,                        # the Spark DataFrame you loaded\n","#     product_key=sample_product,\n","#     store_key=sample_store,\n","#     forecast_horizon=4\n","# )\n","\n","# display(metrics_pdf) "],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":-1,"statement_ids":null,"state":"cancelled","livy_statement_state":null,"session_id":"617ff04b-c95e-41ea-b8e0-1024a6f4188e","normalized_state":"cancelled","queued_time":"2025-06-19T14:29:17.6764465Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2025-06-19T14:30:31.9138369Z","parent_msg_id":"cf290090-0c6d-4183-8216-2b007881fcfb"},"text/plain":"StatementMeta(, 617ff04b-c95e-41ea-b8e0-1024a6f4188e, -1, Cancelled, , Cancelled)"},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"1c1872e9-8f66-41da-8122-4c871efd3d59"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"798eb282-038c-4a0e-bb1f-e1c57f0083f2"}],"default_lakehouse":"798eb282-038c-4a0e-bb1f-e1c57f0083f2","default_lakehouse_name":"Machine_Learning","default_lakehouse_workspace_id":"7dc535a0-d10f-45d2-a704-6132306d730d"}}},"nbformat":4,"nbformat_minor":5}